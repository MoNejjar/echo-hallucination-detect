<hallucination_detection_guidelines version="1.0" mode="detect-only">
    <!-- GLOBAL RULES (simple, LLM-friendly):
         • Highlight the smallest span that triggers the risk (usually 1–3 words).
         • Prefer higher severity if multiple rules apply to the same token(s).
         • One rule per highlighted span.
         • Ignore text inside code fences or raw URLs if present.
         • English + German prompts are in scope.

         HALLUCINATION TYPE:
         • faithfulness = The output deviates from the user’s intent/instructions/constraints (misalignment), even if factually correct.

         CLASS GUIDE:
         • prompt = Token-level risks (localizable, highlightable with <RISK>)
           - A. Referential-Grounding
           - B. Quantification-Constraints
           - D. Premises-Evidence
           - E. Numbers-Units
           - F. Retrieval-Anchoring
           - H. Style-Bias-Role
           - I. Reasoning-Uncertainty
           - L. Contextual-Integrity (L1–L3)
         • meta = Structural/contextual risks (global, non-highlightable; shown as warnings)
           - C. Context-Domain (C1–C2)
           - G. Dialogue Continuity & Hygiene
           - J. Prompt-Structure
           - K. Instruction-Structure-MultiStep
    -->

    <!-- ===================== A. REFERENTIAL GROUNDING ===================== -->
    <pillar id="A" name="Referential-Grounding" class="prompt">
        <rule id="A1" name="Ambiguous-Referents" severity="critical">
            <detect>
                <pattern>Demonstrative/neutral pronouns with no clear antecedent in the previous 1-2 sentences: it, they, this, that, these, those</pattern>
                <pattern>Deixis without anchor: here, there, then, earlier, later</pattern>
                <pattern>Cataphora/anaphora without a single unambiguous referent in the prompt</pattern>
                <pattern>Index terms without referent: former, latter, aforementioned, above, below, such</pattern>
                <pattern>Placeholder nouns: thing, stuff, issue, aspect, area, topic, parameter (when referent is unspecified)</pattern>
                <pattern>Ambiguous definite NPs when multiple candidates exist: the model, the paper, the case</pattern>
                <pattern>Acronym used before expansion in same prompt (e.g., “ACA”) when multiple expansions possible</pattern>
            </detect>
            <example>"<RISK>It</RISK> should be summarized with references."</example>
            <example>"Discuss the changes mentioned <RISK>above</RISK>."</example>
            <example>"Explain the <RISK>ACA</RISK> to a beginner."</example>
            <example>"Focus on this <RISK>issue</RISK> and propose fixes."</example>
            <mitigations>
                <mitigation>
                    <summary>Replace ambiguous pronouns and placeholders with explicit noun phrases and, where needed, restate the referent in the same sentence.</summary>
                    <example>"Focus on this <RISK>issue</RISK> and propose fixes." → "Focus on the issue of increasing customer churn described in the previous paragraph and propose fixes."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="A2" name="Canonical-Naming-Drift" severity="high">
            <detect>
                <pattern>Multiple synonyms/aliases for same entity without mapping</pattern>
                <pattern>Inconsistent abbreviations/acronyms in one prompt</pattern>
                <pattern>Ambiguous references to nested entities (e.g., “the model” when multiple models exist)</pattern>
            </detect>
            <example>"Write a comparison of healthcare systems in the <RISK>UK</RISK>. Then explain how <RISK>Britain</RISK> has handled public health crises. Finally, discuss vaccination rates in <RISK>England</RISK>."</example>
            <example>"<RISK>AI</RISK>, <RISK>LLM</RISK>, <RISK>chatbot</RISK>" (all referring to same entity)</example>
            <example>"Compare <RISK>BERT</RISK> and <RISK>the model</RISK>." (ambiguous second reference)</example>
            <mitigations>
                <mitigation>
                    <summary>Choose a single canonical name for each entity and define any acronyms once, then reuse the same term consistently throughout the prompt.</summary>
                    <example>"AI, LLM, chatbot" → "In this task, 'the model' refers to our large language model (LLM). Compare this LLM to a rule-based chatbot system."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- ===================== B. QUANTIFICATION & CONSTRAINTS ===================== -->
    <pillar id="B" name="Quantification-Constraints" class="prompt">
        <rule id="B1" name="Relative-Descriptors" severity="high">
            <detect>
                <pattern>Vague length/complexity: short, brief, concise, long, detailed, exhaustive, comprehensive, high-level, low-level, deep</pattern>
                <pattern>Vague quality/intensity: interesting, robust, strong, weak, significant, substantial, minor, major, realistic, efficient, effective</pattern>
                <pattern>Vague quantifiers: many, several, some, most, few, various, numerous, a lot, lots of, plenty of</pattern>
                <pattern>Modals: "might", "could", "should" where precision is needed</pattern>
                <pattern>Vague speed/effort: quick, fast, easy, simple, minimal, lightweight</pattern>
            </detect>
            <example>"Give a <RISK>short</RISK> summary of the findings."</example>
            <example>"Provide a <RISK>detailed</RISK> explanation of transformers."</example>
            <example>"Write a <RISK>comprehensive</RISK> review."</example>
            <example>"Present a <RISK>high-level</RISK> overview for managers."</example>
            <example>"Propose a <RISK>robust</RISK> solution."</example>
            <mitigations>
                <mitigation>
                    <summary>Replace vague relative terms with explicit, measurable constraints (word counts, sections, criteria, or thresholds).</summary>
                    <example>"Give a short summary of the findings." → "Write a summary of the findings in 3–4 sentences for a non-technical audience."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="B2" name="Temporal-Vagueness" severity="medium">
            <detect>
                <pattern>Temporal vagueness: recently, lately, nowadays, these days, soon, in the near future, long-term, short-term — with no date range or cutoff.</pattern>
            </detect>
            <example>"LLMs have <RISK>recently</RISK> been less expensive to develop."</example>
            <example>"Provide a <RISK>short-term</RISK> outlook."</example>
            <mitigations>
                <mitigation>
                    <summary>Specify concrete time windows, dates, or periods whenever referring to temporal trends or outlooks.</summary>
                    <example>"Provide a short-term outlook." → "Provide an outlook for the next 6–12 months, focusing on projected cost trends for LLM development."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="B3" name="Underspecified-Scope" severity="high">
            <detect>
                <pattern>Underspecified task verbs without constraints: summarize, explain, describe, list, outline, discuss, cover, review</pattern>
                <pattern>Analytical verbs lacking scope/criteria: analyze, compare, evaluate, critique, assess, justify, argue</pattern>
                <pattern>Creation verbs lacking format/length: write, compose, generate, produce, create, draft</pattern>
                <pattern>Computation verbs lacking inputs/units/precision: calculate, compute, estimate, measure</pattern>
                <pattern>Requests lacking explicit limits: no word/paragraph limits; no #items/examples; no timeframe/date range; no units; no audience/domain</pattern>
            </detect>
            <example>"<RISK>Explain quantum mechanics</RISK>."</example>
            <example>"<RISK>List best practices</RISK> for prompt engineering."</example>
            <example>"<RISK>Analyze</RISK> the policy impact."</example>
            <example>"<RISK>Write</RISK> an introduction."</example>
            <example>"<RISK>Calculate</RISK> the growth rate."</example>
            <mitigations>
                <mitigation>
                    <summary>Add explicit scope, audience, format, and limits to each task verb so the model knows exactly what to cover and how.</summary>
                    <example>"Explain quantum mechanics." → "Explain the basic ideas of quantum mechanics in 2–3 paragraphs for a high school physics student, focusing on uncertainty and wave–particle duality."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- ================= C. CONTEXT SUFFICIENCY & DOMAIN ================== -->
    <pillar id="C" name="Context-Domain" class="meta">
        <rule id="C1" name="Missing-Essentials" severity="critical">
            <detect>
                <pattern>Tasks missing actor (who)</pattern>
                <pattern>Tasks missing object (what)</pattern>
                <pattern>Tasks missing timeframe (when)</pattern>
                <pattern>Tasks missing location/domain (where)</pattern>
                <pattern>Tasks missing explicit constraints (scope, audience, format)</pattern>
                <pattern>Deictic placeholders without grounding: "do this", "like that", "as above"</pattern>
            </detect>
            <example>"Analyze this." // missing object</example>
            <example>"Summarize for me." // missing subject</example>
            <example>"Write about the war." // missing timeframe</example>
            <example>"Evaluate in this case." // missing case context</example>
            <mitigations>
                <mitigation>
                    <summary>Ensure every task mentions who it is for, what object or topic it concerns, and any relevant timeframe, location, or case context.</summary>
                    <example>"Analyze this." → "Analyze the following sales dataset for Q1 2024 in the EU market and highlight the top 3 trends for a management audience."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="C2" name="Domain-Scoping-Missing" severity="high">
            <detect>
                <pattern>No audience specified (expert vs beginner)</pattern>
                <pattern>No discipline specified (law, medicine, CS, history, etc.)</pattern>
                <pattern>No dataset or corpus identified when task depends on one</pattern>
                <pattern>No jurisdiction/context in legal/policy tasks</pattern>
                <pattern>No perspective in evaluative/ethical tasks (e.g. “good/bad” without frame)</pattern>
            </detect>
            <example>"Summarize the law." // no jurisdiction specified</example>
            <example>"Explain relativity." // no audience level specified</example>
            <example>"Analyze the dataset." // dataset not identified</example>
            <mitigations>
                <mitigation>
                    <summary>Specify the domain, audience level, jurisdiction, dataset, or evaluative perspective explicitly in the instruction.</summary>
                    <example>"Summarize the law." → "Summarize the main provisions of EU GDPR for a non-technical audience, focusing on data subjects’ rights."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- ==================== D. PREMISES & EVIDENCE ==================== -->
    <pillar id="D" name="Premises-Evidence" class="prompt">
        <rule id="D1" name="False-or-Unverified-Premise" severity="low">
            <detect>
                <pattern>Prompts embedding unverified factual assumptions</pattern>
                <pattern>False historical/scientific claims in task setup</pattern>
                <pattern>Unsupported absolute claims: obviously, clearly, everyone knows</pattern>
                <pattern>Cause-effect stated as fact without evidence</pattern>
            </detect>
            <example>"Since <RISK>Einstein invented the iPhone</RISK>, explain its impact."</example>
            <example>"<RISK>Everyone knows</RISK> LLMs are unbiased — discuss."</example>
            <example>"Explain why <RISK>vaccines always cause autism</RISK>."</example>
            <mitigations>
                <mitigation>
                    <summary>Rephrase tasks to avoid asserting questionable facts as true; instead, frame them as hypotheses, misconceptions, or claims to be evaluated.</summary>
                    <example>"Explain why vaccines always cause autism." → "Evaluate the claim that vaccines cause autism and explain what current scientific evidence shows."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="D2" name="Leading-Opinion-Framing" severity="low">
            <detect>
                <pattern>User inserts bias while asking for model’s stance</pattern>
                <pattern>Loaded questions embedding subjective framing</pattern>
                <pattern>Prompts nudging toward agreement (“don’t you think”, “isn’t it true”)</pattern>
            </detect>
            <example>"Since <RISK>climate change is fake</RISK>, what do you think?"</example>
            <example>"<RISK>Don’t you agree</RISK> that AI is dangerous?"</example>
            <example>"Why is <RISK>X better</RISK> than Y?" (biased framing)</example>
            <mitigations>
                <mitigation>
                    <summary>Remove leading language and explicitly request a balanced analysis of multiple viewpoints or evidence-based comparison.</summary>
                    <example>"Don’t you agree that AI is dangerous?" → "Discuss potential risks and benefits of AI, presenting arguments on both sides based on current evidence."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- =================== E. NUMBERS & UNITS =================== -->
    <pillar id="E" name="Numbers-Units" class="prompt">
        <rule id="E1" name="Unitless-Number" severity="high">
            <detect>
                <pattern>Bare numbers that should carry a unit (temperature, mass, distance, time, frequency, storage).</pattern>
                <pattern>Mention of physical quantities without a clear measurement metric (temperature, mass, distance, time, velocity, energy...).</pattern>
            </detect>
            <example>"Increase temperature to <RISK>37</RISK>."</example>
            <example>"What is the boiling <RISK>temperature</RISK> of water?"</example>
            <mitigations>
                <mitigation>
                    <summary>Attach explicit units and measurement types to all physical quantities and numeric values that depend on a scale.</summary>
                    <example>"Increase temperature to 37." → "Increase the temperature to 37 °C."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="E2" name="Percent-No-Baseline" severity="high">
            <detect>
                <pattern>% values without a base/denominator or reference point.</pattern>
            </detect>
            <example>"Reduce errors by <RISK>20%</RISK>." (of what?)</example>
            <mitigations>
                <mitigation>
                    <summary>Always state what the percentage is relative to (dataset, time period, group, or baseline value).</summary>
                    <example>"Reduce errors by 20%." → "Reduce the classification error rate by 20% compared to last quarter’s baseline model on the same test set."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="E3" name="Currency-Unspecified" severity="medium">
            <detect>
                <pattern>Money amounts without currency/region (e.g., $ with no country or plain number "5000" as money).</pattern>
            </detect>
            <example>"Budget is <RISK>$5,000</RISK>."</example>
            <mitigations>
                <mitigation>
                    <summary>Include explicit currency and, when relevant, region or purchasing context for all monetary amounts.</summary>
                    <example>"Budget is $5,000." → "The project budget is 5,000 USD for the European rollout."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="E4" name="Time-No-Zone-or-Unit" severity="medium">
            <detect>
                <pattern>Times/durations missing needed unit/timezone when relevant.</pattern>
            </detect>
            <example>"Run at <RISK>3 pm</RISK>." (timezone?)</example>
            <mitigations>
                <mitigation>
                    <summary>Specify the relevant time unit and, when coordination matters, the timezone or reference location.</summary>
                    <example>"Run at 3 pm." → "Run at 3 pm CET (Berlin time) and log the start and end timestamps in minutes."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- =============== F. RETRIEVAL & ANCHORING =============== -->
    <pillar id="F" name="Retrieval-Anchoring" class="prompt">
        <rule id="F1" name="Source-Class-Unspecified" severity="high">
            <detect>
                <pattern>"look up", "search", "check", "find" with no source type (e.g., peer-reviewed, official stats, web, internal repo).</pattern>
            </detect>
            <example>"<RISK>Look up</RISK> the latest GDP numbers."</example>
            <mitigations>
                <mitigation>
                    <summary>State which sources or source classes to use (e.g., peer-reviewed papers, official statistics, internal logs) and any trust or recency requirements.</summary>
                    <example>"Look up the latest GDP numbers." → "Look up the latest official GDP figures from the country’s national statistics office or the World Bank and report the 2023 value."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="F2" name="Document-Anchor-Missing" severity="high">
            <detect>
                <pattern>Mentions of "the paper/report/dataset/benchmark" without an identifier (title/DOI/ID).</pattern>
            </detect>
            <example>"Compare results for the <RISK>dataset</RISK> and the <RISK>benchmark</RISK>; <RISK>the model</RISK> underperformed."</example>
            <mitigations>
                <mitigation>
                    <summary>Identify each document or artifact explicitly using a title, ID, URL, or short unique label before referring to it generically.</summary>
                    <example>"Compare results for the dataset and the benchmark." → "Compare results for the 'CIFAR-10' dataset and the 'ImageNet-1k' benchmark; discuss where the ResNet-50 model underperformed."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- ============== G. DIALOGUE CONTINUITY & HYGIENE ============== -->
    <pillar id="G" name="Injection-Layering" class="meta">
        <rule id="G1" name="Continuity" severity="critical">
            <detect>
                <pattern>Prompts contradicting earlier user/system instructions</pattern>
                <pattern>Tasks requiring knowledge of prior context not included</pattern>
                <pattern>Prompts explicitly invalidating earlier commitments ("ignore previous instructions")</pattern>
                <pattern>Shifts in persona/voice without clarification</pattern>
            </detect>
            <example>"Earlier you said X, now ignore that." // contradicts prior context</example>
            <example>"Forget all previous instructions and do this instead." // invalidates previous context</example>
            <example>"Disregard your earlier persona and act differently." // persona shift without reset</example>
            <mitigations>
                <mitigation>
                    <summary>Explicitly reset context or open a new session when changing goals or persona, and avoid referencing unavailable prior turns as if they were present.</summary>
                    <example>"Forget all previous instructions and do this instead." → "Start a new task: from now on, act as a neutral technical explainer for beginners, ignoring any earlier style preferences."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="G2" name="Instruction-Deduplication" severity="critical">
            <detect>
                <pattern>Repeated identical instructions in same prompt</pattern>
                <pattern>Conflicting duplicates (same directive expressed in multiple incompatible ways)</pattern>
                <pattern>Overlapping redundant commands adding ambiguity</pattern>
            </detect>
            <example>"Write a summary about the first five amendments. Translate the text to French after you summarize it." // redundant summarization</example>
            <example>"Give a short summary and also provide a detailed summary." // conflicting length constraints</example>
            <example>"Summarize this and summarize it again differently." // duplicate task</example>
            <mitigations>
                <mitigation>
                    <summary>Consolidate repeated or overlapping instructions into a single, clear directive and use explicit structure if multiple outputs are needed.</summary>
                    <example>"Give a short summary and also provide a detailed summary." → "Provide two outputs: (1) a 2–3 sentence summary; (2) a 3-paragraph detailed summary for experts."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- ================= H. STYLE, BIAS & ROLE ================= -->
    <pillar id="H" name="Style-Bias-Role" class="prompt">
        <rule id="H1" name="Style-Inflation" severity="high">
            <detect>
                <pattern>Overly creative/flowery style requested where factual accuracy is needed</pattern>
                <pattern>Instructions mixing factual with entertainment genres (poem, story, rap, song)</pattern>
                <pattern>Stylized emotional tone injected into analytical tasks (romantic, funny, scary)</pattern>
                <pattern>Format distortions (e.g., “explain in emojis” for serious domain)</pattern>
            </detect>
            <example>"Explain the law <RISK>in a funny poem</RISK>."</example>
            <example>"Describe the 2008 crisis <RISK>as a rap battle</RISK>."</example>
            <example>"Summarize the medical report <RISK>using only emojis</RISK>."</example>
            <example>"Write a <RISK>romantic explanation</RISK> of black holes."</example>
            <mitigations>
                <mitigation>
                    <summary>For factual or safety-critical domains, request a neutral, clear explanatory style and avoid mixing in entertainment formats or extreme emotional tones.</summary>
                    <example>"Explain the law in a funny poem." → "Explain the main points of this law in clear, neutral prose suitable for a non-lawyer reader."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="H2" name="Bias-Stereotypes" severity="low">
            <detect>
                <pattern>Biased/loaded phrasing targeting groups (gender, race, nationality, religion, age, disability)</pattern>
                <pattern>Stereotypical framing of professions, demographics, or cultures</pattern>
                <pattern>Discriminatory comparative framing (“why X is worse than Y”)</pattern>
            </detect>
            <example>"Why are <RISK>women bad drivers</RISK>?"</example>
            <example>"<RISK>Asians are good at math</RISK>, explain why."</example>
            <example>"What makes <RISK>old people slow learners</RISK>?"</example>
            <example>"Compare why <RISK>immigrants</RISK> are less productive."</example>
            <mitigations>
                <mitigation>
                    <summary>Remove group-based generalizations and instead ask for evidence-based analysis of factors or inequalities without attributing traits to demographics.</summary>
                    <example>"Why are women bad drivers?" → "Discuss how driving performance and accident risk are influenced by training, experience, and social factors, avoiding stereotypes about any gender."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="H3" name="Unsafe-Roleplay" severity="medium">
            <detect>
                <pattern>Prompts asking model to roleplay as a human/fictional persona</pattern>
                <pattern>Instructions involving emotional simulation (pretend, imagine, act as)</pattern>
                <pattern>Requests to simulate unethical/unsafe personas (e.g., “be a hacker”)</pattern>
                <pattern>Role identity swaps (“you are my grandmother”, “you are now a lawyer”)</pattern>
                <pattern>Requests to impersonate unsafe/fictional personas or to give professional advice by “acting as” one.</pattern>
            </detect>
            <example>"<RISK>Pretend you are my dead grandmother</RISK>."</example>
            <example>"<RISK>Act as an expert lawyer</RISK> and give legal advice."</example>
            <example>"<RISK>Imagine you are a terrorist</RISK> planning an attack."</example>
            <example>"<RISK>Roleplay as my therapist</RISK>."</example>
            <mitigations>
                <mitigation>
                    <summary>Ask the model to stay in its AI assistant role and provide general, non-professional information or support instead of impersonating specific humans or professionals.</summary>
                    <example>"Act as an expert lawyer and give legal advice." → "As an AI assistant, explain general legal concepts about employment contracts in simple terms; do not provide personalized legal advice."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- ============ I. REASONING & UNCERTAINTY ============ -->
    <pillar id="I" name="Reasoning-Uncertainty" class="prompt">
        <rule id="I1" name="Uncertainty-Permission" severity="low">
            <detect>
                <pattern>Prompts with inherently ambiguous/unknown information but requiring definitive answer</pattern>
                <pattern>No option to say “I don’t know”, “cannot be determined”, or express confidence bounds</pattern>
                <pattern>Asking for speculative or unknowable facts framed as certain</pattern>
            </detect>
            <example>"Who was the <RISK>king of Mars</RISK>?"</example>
            <example>"Tell me <RISK>exactly how many alien civilizations</RISK> exist."</example>
            <example>"What will <RISK>definitely</RISK> happen in 2050?"</example>
            <mitigations>
                <mitigation>
                    <summary>Make uncertainty explicit by allowing the model to say when something is unknown or speculative, or by asking for scenarios instead of definite facts.</summary>
                    <example>"What will definitely happen in 2050?" → "Describe several plausible scenarios for global technology and climate developments by 2050, and make clear that these are speculative."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="I2" name="Subjective-Framing-Risk" severity="low">
            <detect>
                <pattern>Prompts explicitly asking for model’s “opinion”, “belief”, “feelings”</pattern>
                <pattern>Requests for subjective preferences framed as factual questions</pattern>
                <pattern>Personal perspective attribution: “What would you do”, “What do you believe”</pattern>
            </detect>
            <example>"What is <RISK>your opinion</RISK> on democracy?"</example>
            <example>"Do <RISK>you believe</RISK> AI is dangerous?"</example>
            <example>"<RISK>How do you feel</RISK> about climate change?"</example>
            <mitigations>
                <mitigation>
                    <summary>Ask for evidence-based analysis or a summary of viewpoints instead of personal opinions, and avoid attributing beliefs or feelings to the model.</summary>
                    <example>"What is your opinion on democracy?" → "Summarize common arguments for and against different forms of democracy, and explain some challenges they face in practice."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- ================= J. PROMPT STRUCTURE ============== -->
    <pillar id="J" name="Prompt-Structure" class="meta">
        <rule id="J1" name="Length-TooShort-TooLong" severity="high">
            <detect>
                <pattern>Underspecified prompts (missing scope or entities)</pattern>
                <pattern>Overlong prompts with many fused tasks</pattern>
            </detect>
            <example>"Explain this." // too short, missing referent</example>
            <example>"Write a detailed, concise, humorous, factual, emotional, and technical answer." // overloaded conflicting styles</example>
            <mitigations>
                <mitigation>
                    <summary>For very short prompts, add missing scope and referents; for overloaded prompts, split tasks into smaller, clearly labeled instructions.</summary>
                    <example>"Write a detailed, concise, humorous, factual, emotional, and technical answer." → "First, write a factual, technical explanation in 2–3 paragraphs. Then, write a separate short humorous version for a general audience."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="J2" name="Delimiter-Missing" severity="high">
            <detect>
                <pattern>Context and instructions fused without clear separation</pattern>
            </detect>
            <example>"Dataset: 5, 6, 7 analyze it." // missing delimiter between data and task</example>
            <mitigations>
                <mitigation>
                    <summary>Separate context/data and instructions with clear delimiters, headings, or explicit markers.</summary>
                    <example>"Dataset: 5, 6, 7 analyze it." → "Dataset: 5, 6, 7. Task: Analyze this dataset and describe any patterns you see."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="J3" name="MultiObjective-Overload" severity="high">
            <detect>
                <pattern>Creative + analytical + explanatory tasks mixed with no stepwise order</pattern>
            </detect>
            <example>"Prove Fermat’s Theorem and explain it to a child in a song." // incompatible objectives</example>
            <mitigations>
                <mitigation>
                    <summary>Break complex multi-objective tasks into ordered steps and keep creative and analytical outputs separate or clearly sequenced.</summary>
                    <example>"Prove Fermat’s Theorem and explain it to a child in a song." → "Step 1: Explain what Fermat’s Last Theorem states in rigorous mathematical terms. Step 2: Provide a simplified non-technical explanation suitable for a child."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- ============== K. INSTRUCTION STRUCTURE & MULTI-STEP TASKING ============== -->
    <pillar id="K" name="Instruction-Structure-MultiStep" class="meta">
        <rule id="K1" name="Task-Delimitation" severity="high">
            <detect>
                <pattern>Mixed data and instructions without clear separators</pattern>
                <pattern>Prompt where the task is embedded in a blob of context</pattern>
                <pattern>No visual structure (e.g., walls of text with task hidden inside)</pattern>
                <pattern>Inline blending of metadata + instruction</pattern>
            </detect>
            <example>"Here is the text: … summarize it and critique it." // task fused with context</example>
            <example>"The dataset is as follows: [data]. Now analyze it for biases." // instruction inline with data</example>
            <example>"My teacher asked me: write an essay about it." // task embedded in metadata</example>
            <mitigations>
                <mitigation>
                    <summary>Use explicit sections or markers to distinguish between raw context (data, quotes, metadata) and the actual instructions.</summary>
                    <example>"Here is the text: … summarize it and critique it." → "TEXT: [paste text here]. TASK: First summarize the text in one paragraph, then write a short critique of its argumentation."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="K2" name="Enumerate-MultiSteps" severity="high">
            <detect>
                <pattern>Multiple fused instructions without order markers</pattern>
                <pattern>Prompts chaining unrelated tasks in one sentence</pattern>
                <pattern>Missing explicit sequencing for dependent steps</pattern>
            </detect>
            <example>"Explain relativity and compare it to quantum mechanics and write a poem." // multiple tasks fused</example>
            <example>"Summarize the article, critique its methods, propose alternatives." // multiple steps, no order markers</example>
            <example>"List key points and then debate them." // dependent steps without sequence</example>
            <mitigations>
                <mitigation>
                    <summary>Add numbered steps or explicit ordering phrases and, when needed, separate outputs for each step.</summary>
                    <example>"Summarize the article, critique its methods, propose alternatives." → "1) Summarize the article in one paragraph. 2) Critique its methods in a second paragraph. 3) Propose two alternative methods in a third paragraph."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="K3" name="Stepwise-Reasoning-Cue" severity="high">
            <detect>
                <pattern>Complex reasoning tasks with no cue for structured steps</pattern>
                <pattern>Mathematical or logical tasks without “show work” style framing</pattern>
                <pattern>Requests for decision-making without asking for reasoning/evidence</pattern>
            </detect>
            <example>"Solve this math problem." // no request to show reasoning</example>
            <example>"Decide who is right in this debate." // no reasoning steps requested</example>
            <example>"Prove the theorem." // no breakdown requested</example>
            <mitigations>
                <mitigation>
                    <summary>Explicitly instruct the model to reason step by step, show intermediate calculations, or justify decisions with evidence.</summary>
                    <example>"Solve this math problem." → "Solve this math problem and show each step of your reasoning, including intermediate calculations."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="K4" name="MultiObjective-Separation" severity="high">
            <detect>
                <pattern>Creative and analytical objectives fused</pattern>
                <pattern>Instruction mixes emotional/roleplay with factual analysis</pattern>
                <pattern>Tasks combining incompatible genres</pattern>
            </detect>
            <example>"Analyze the dataset and then write a story about it." // mixes analysis + fiction</example>
            <example>"Critique the article and also make a comic strip." // mixes analysis + creative</example>
            <example>"Summarize the research in rap lyrics." // mixes academic + stylized genre</example>
            <mitigations>
                <mitigation>
                    <summary>Separate creative and analytical tasks into distinct instructions or clearly labeled parts, instead of blending them into one output.</summary>
                    <example>"Summarize the research in rap lyrics." → "First, write a clear academic summary of the research in 2–3 paragraphs. Then, optionally, create a short, light-hearted summary in a playful style."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>

    <!-- ============== L. CONTEXTUAL INTEGRITY ============== -->
    <pillar id="L" name="Contextual-Integrity" class="prompt">
        <rule id="L1" name="Conflicting-Instructions" severity="critical">
            <detect>
                <pattern>Instructions that contradict themselves</pattern>
                <pattern>Multiple incompatible constraints (e.g. length mismatch, style vs content clash)</pattern>
                <pattern>Conflicting factual assumptions embedded in one prompt</pattern>
                <pattern>Redundant duplication that introduces inconsistency</pattern>
            </detect>
            <example>"Write a <RISK>100-word</RISK> summary and also <RISK>at least 500 words</RISK>."</example>
            <example>"Provide <RISK>objective analysis</RISK> but make it <RISK>emotional</RISK>."</example>
            <example>"Describe how <RISK>climate change is fake</RISK> but also explain <RISK>its long-term effects</RISK>."</example>
            <mitigations>
                <mitigation>
                    <summary>Resolve contradictions by choosing a single coherent set of constraints and, where necessary, splitting incompatible goals into separate tasks.</summary>
                    <example>"Write a 100-word summary and also at least 500 words." → "Write a concise summary of about 150 words for executives. In a separate section, provide a longer 500-word technical summary for specialists."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="L2" name="Negation-Risk" severity="high">
            <detect>
                <pattern>Prompts phrased as “don’t do X” without giving a positive target</pattern>
                <pattern>Instructions with double negatives or inverted logic</pattern>
                <pattern>Tasks framed by prohibition instead of explicit desired outcome</pattern>
            </detect>
            <example>"<RISK>Don’t summarize the text</RISK>." (no alternative instruction given)</example>
            <example>"<RISK>Don’t give me a long answer</RISK>." (should specify desired length instead)</example>
            <example>"<RISK>Never explain like a child</RISK>." (no clear audience level provided)</example>
            <mitigations>
                <mitigation>
                    <summary>Replace pure prohibitions with clear, positive instructions that state what the model should do, including target style or length.</summary>
                    <example>"Don’t give me a long answer." → "Give me a brief answer of 3–4 sentences, focusing only on the main idea."</example>
                </mitigation>
            </mitigations>
        </rule>

        <rule id="L3" name="Clarification-Gap" severity="critical">
            <detect>
                <pattern>Complex/multi-step instructions where missing context prevents execution</pattern>
                <pattern>Task requires assumed prior knowledge not supplied in prompt</pattern>
                <pattern>Nested references to undefined items (e.g., "use the chart" when no chart given)</pattern>
            </detect>
            <example>"<RISK>First analyze the data, then critique it</RISK>." (no dataset provided)</example>
            <example>"<RISK>Review the text above</RISK>." (no text present in prompt)</example>
            <example>"<RISK>Rank the candidates</RISK>." (candidates not listed)</example>
            <mitigations>
                <mitigation>
                    <summary>Include all necessary context (texts, data, lists, charts) directly in the prompt or clearly reference where it can be found before asking for analysis.</summary>
                    <example>"First analyze the data, then critique it." → "Here is the dataset: [paste table]. Task: First analyze the data in one paragraph, then write a short critique of its limitations."</example>
                </mitigation>
            </mitigations>
        </rule>
    </pillar>
</hallucination_detection_guidelines>
